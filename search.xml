<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Pytorch教程-第二回]]></title>
    <url>%2Fpost%2F%5B20190531%5DPytorch%E6%95%99%E7%A8%8B-%E7%AC%AC%E4%BA%8C%E5%9B%9E%2F</url>
    <content type="text"><![CDATA[写在前面 李阿将在这一章中讲解Lenet5的简易版具体实现pytorch实现和训练过程。将在下一回学习高级版实现，即自定义数据集的训练，模型保存加载，可视化等功能。 数据集的读取 为了更好的学习pytorch，在这里mnist的读取采用自定义数据源的读取。创建一个read_data.py文件，用以加载mnist数据。 1234567891011121314151617181920import gzip, structimport numpy as np# gzip为python的一个解压缩的库函数，struct为一个数据处理的库def _read(image, label): mnist_dir = &quot;./data/&quot; with gzip.open(mnist_dir + label) as flbl: magic, num = struct.unpack(&quot;&gt;II&quot;, flbl.read(8)) lable = np.fromstring(flbl.read(), dtype=np.int8) with gzip.open(mnist+dir + label, &apos;rb&apos;) as fimg: magic, num, rows, cols = struct.unpack(&quot;&gt;III&quot;, fimg.read(16)) image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols) return image,labeldef get_data(): train_img,train_label = _read( &apos;train-images-idx3-ubyte.gz&apos;, &apos;train-labels-idx1-ubyte.gz&apos;) test_img,test_label = _read( &apos;t10k-images-idx3-ubyte.gz&apos;, &apos;t10k-labels-idx1-ubyte.gz&apos;) return [train_img,train_label,test_img,test_label] 接下来就是使用pytorch实现LeNet部分。也就是我们第一回所学习的。直接copy过来。 模型定义1234567891011121314151617181920212223242526import torchimport torch.nn as nnfrom torch.nn import functional as Fclass LeNet5(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 6, 5, padding=2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16*5*5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2)) x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(self, x): size = x.size()[1:] num_features = 1 for s in size: num_features *= s return num_features 接下来就是主要部分了，训练和测试。 训练和测试12345678910111213141516171819202122232425262728293031323334353637383940414243444546from torch.utils.data import TensorDataset, DataLoaderfrom torchvision import transformsfrom read_data import get_datafrom torch.autograd import Variable&apos;&apos;‘TensorDataset包转数据和目标张量的数据集，通过第一个维度索引两个张量来恢复每个样本。class torch.utils.data.TensorDataset(data_tensor, target_tensor)DataLoader数据加载器，组合数据集和采样器，并在数据集上提供单进程或者多进程迭代器。class torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, num_workers=0, collate_fn=&lt;function default_collate&gt;, pin_memory=False, drop_last=False)个别参数解释：sampler定义从数据集中提取样本的策略，如果指定，则忽略shffle参数。num_workers：用多少个子进程加载数据，0表示数据将在主进程中加载pin_memory:是否将tensor数据复制到CUDA pinned memory中，pin memory中的数据转到GPU中会快一些collate_fn:把一组samples打包成一个mini-batch的函数，可以自定义这个函数以处理损害数据的情况（先在__getitem__函数中将这样的数据返回None，然后再在collate_fn中处理，如丢掉损坏数据or再从数据集里随机挑一张）drop_last：数据集不能整除batch size时候，是不是把其丢掉&apos;&apos;&apos;&apos;&apos;‘torchvision是独立于pytorch的关于图像操作的一些方便工具库主要有以下几个包：vision.datasets : 几个常用视觉数据集，可以下载和加载，这里主要的高级用法就是可以看源码如何自己写自己的Dataset的子类vision.models : 流行的模型，例如 AlexNet, VGG, ResNet 和 Densenet 以及 与训练好的参数。vision.transforms : 常用的图像操作，例如：随机切割，旋转，数据类型转换，图像到tensor ,numpy 数组到tensor , tensor 到 图像等。vision.utils : 用于把形似 (3 x H x W) 的张量保存到硬盘中，给一个mini-batch的图像可以产生一个图像格网。&apos;&apos;’use_gpu = torch.cuda.is_available()batch_size = 256kwargs = &#123;&apos;num_workers&apos;: 2, &apos;pin_memory&apos;: True&#125; if use_gpu else &#123;&#125;#数据集加载X, y, Xt, yx = get_data()train_x, train_y = torch.from_numpy(X.reshape(-1, 1, 28, 28)).float(), torch.from_numpy(y.astype(int))test_x, test_y = [ torch.from_numpy(Xt.reshape(-1, 1, 28, 28)).float(), torch.from_numpy(yt.astype(int)) ]train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size, **kwargs)test_loader = DataLoader(dataset=test_dataset, shuffle=True, batch_size=batch_size, **kwargs)model = LeNet5()if use_gpu: model = model.cuda() #将所有模型参数复制到Gpu print(&apos;USE GPU&apos;)else: print(&apos;USE CPU&apos;)criterion = nn.CrossEntropyLoss(size_average=False)optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.99)) 在上面的代码中用到了model.cuda，是这torch.nn.module的一个函数，module是所有网络的基类，实际意义代表一层或者多层的网络。下面继续码代码： 1234567891011def weight_init(m): #定义权重初始化函数 if isinstance(m, nn.Conv2d): import math n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels m.weight.data.normal_(0, math.sqrt(2./n)) elif isinstance(m, nn.BatchNorm2d): m.weight.data.fill_(1) m.bias.data.zero_() model.apply(weight_init)#apply函数会递归地搜索网络内的所有module并把参数表示的函数应用到所有的module上。 网络搭建好了，数据读取已经定义好了，参数已经初始化，就等训练啦！！！ 1234567891011121314151617181920212223242526272829303132333435363738def train(epoch): model.train() #将module设置为训练模式，对dropout和bn产生影响 for batch_idx, (data, target) in enumerate(train_loader): if use_gpu: data, target = data.cuda(), target.cuda() #将数据转到GPU上 data, target = Variable(data), Variable(target)&apos;&apos;‘torch.autograd.Variable用来包裹张量并记录应用的操作。 Variable可以看作是对Tensor对象周围的一个薄包装，也包含了和张量相关的梯度，以及对创建它的函数的引用。 此引用允许对创建数据的整个操作链进行回溯。需要BP的网络都是通过Variable来计算的。&apos;&apos;’ optimizer.zero_grad() output = model(data) loss = criterion(output, target) loss.backward() optimizer.step() if batch_idx % 100 == 0: print(&apos;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&apos;.format(epoch, batch_idx * len(data), len(train_loader.dataset),100. * batch_idx / len(train_loader), loss.data[0])) def test(): model.eval() test_loss = 0 correct = 0 for data, target in test_loader: if use_gpu: data, target = data.cuda(), target.cuda() data, target = Variable(data, volatile=True), Variable(target) output = model(data) test_loss += criterion(output, target).data[0] pred = output.data.max(1, keepdim=True)[1] #返回第一维中每行最大值和索引，keepdim=True表示输出张量除了被操作的dim维度值为1其他不变 correct += pred.eq(target.data.view_as(pred)).cpu().sum() test_loss /= len(test_loader.dataset) print(&apos;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.2f&#125;%)\n&apos;.format( test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset))) 所有的一切已经定义就绪，接下来就是运行： 123for epoch in range(1, 501): train(epoch) test() 至此已经学习完简易版的lenet5的pytorch实现了，接下来一回将讲解高级版，包括自定义数据集训练，模型保存加载，可视化等功能。 再次特意感谢知乎战歌指挥官文章，本文参考自其文章。]]></content>
      <categories>
        <category>学习笔记</category>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch教程-第一回]]></title>
    <url>%2Fpost%2F%5B20190530%5DPytorch%E6%95%99%E7%A8%8B-%E7%AC%AC%E4%B8%80%E5%9B%9E%2F</url>
    <content type="text"><![CDATA[写在前面 李阿将在这一系列文章中和大家一起从头学习Pytorch。和别的教程开始先简介一些基本的tensor之类的基础定义不同的是，李阿将直接从LeNet5实现开始讲解，在基本定义穿插在LeNet5实现中，之后在介绍基本知识，然后以一进阶的网络实现结束Pytorch的学习。 不知道大家有没有接触过LeNet5网络,就当大家已经知晓LeNet5了吧？不如是小白，请百度之后再回来。 Forward 的建立123456789101112import torchimport torch.nn as nnimport torch.nn.functional as F#Torch.nn.functional中定义了卷积等等很多的操作class Net(nn.Module): # nn.Module是所有神经网络的父类 def __init_(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(1, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) &emsp;&emsp;在这里定义了一个卷积层，输入channel为1，输出channels为6，卷积核大小为55。函数定义为：*torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride = 1,padding=0, dilation=1, groups=1, bias=True)&emsp;&emsp;其中：in_channels:输入通道数，out_channels:输出通道数，kernel_size:卷积核尺寸，stride：步长，padding:输入数据各个维度各个边要补齐的层数，dilation：卷积核各元素之间的距离，group：输入通道和输出通道之间相互隔离的连接的个数，bias：如果被置为True，向输出增加一个偏差量，此偏差是可以学习的参数。&emsp;&emsp;重点解释下group参数的含义，group必须同时被in_channels and out_channels整除，表示控制了输入输出之间的连接数量。&emsp;&emsp;conv2d的卷积核size为[out_channels, in_channels, kernel_size, kernel_size]&emsp;&emsp;conv = nn.Conv2d(in_channels=6, out_channels=6, kernel_size=1, groups=1)&emsp;&emsp;conv.weight.data.size()&emsp;&emsp;得到的输出结果为torch.Size([6, 6, 1, 1])&emsp;&emsp;而当其中group参数分别为2，3，6时输出结构为：&emsp;&emsp;torch.Size([6,3,1,1])&emsp;&emsp;torch.Size([6,2,1,1])&emsp;&emsp;torch.Size([6,1,1,1])&emsp;&emsp;当group=1的时候,卷积核为[6,6,1,1]，即对于每一个特征图[6, $H_{in}$,$W_{in}$]乘以[6，1，1]的卷积核得到[1, $H_{out}$, $W_{out}$]，经过6次这样的计算得到6个特征图。 &emsp;&emsp;而当group=2的时候，相当于卷积核为[6,3,1,1]，输入会被分为两个部分2[3, $H_{in}$,$W_{in}$], 每个部分都与卷积核2[3,3,1,1]相乘,得到两个[3, $H_{out}$, $W_{out}$]的输出，在concat得到结果。123self.fc1 = nn.Linear(16*5*5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) nn.Linear(in_features, out_features),公式如下$output = input * weight + bias$​ Examples:​ >&gt;&gt; m = nn.Linear(20, 30)​ >&gt;&gt; input = torch.randn(128, 20)​ >&gt;&gt; output = m(input)​ >&gt;&gt; print(output.size())​ torch.Size([128, 30]) 123def forward(self, x): x = F.max_pool2d(F.relu(self.conv1(x)), (2,2)) x = F.max_pool2d(F.relu(self.conv2(x), 2)) max_pool2d最大池化卷积，定义如下：max_pool2d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False)解释下这里的ceil_mode但其为True时候，会把不能被kernel整除的边保留下来，也可以理解为原来的边上pad了-NAN的边，即向上取整，而为False着表示为floor模式，就把上面的边舍去了return_indices如果等于True，会返回输出最大值的序号，对于上采样操作会有帮助。如果为kernel为一个正方形的话，size项可以用一个数表示，即源代码中的2 123456789101112131415 x = x.view(-1, self.num_flat_features(x)) &apos;&apos;&apos;num_flat_features定义应该在该函数结束之后实现，为了直观观看，现在改在注释中： def num_flat_features(self, x): size = x.size()[1:] num_features = 1 for s in size: num_features *= s return num_features &apos;&apos;&apos; x = F.relu(self.fc1(x)) F.relu(self.fc2(x)) x = self.fc3(x) return xnet = Net()print(net) 输出如下：1234567Net( (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True)) 恭喜！现在我们已经网络了前向网络的搭建了，下面将介绍损失函数,反向传播: 损失函数 nn包中有不同的损失函数，这这里使用nn.MSELoss。 123456output = net(input)target = torch.randn(10) #假定一个目标函数target = target.view(1,-1)criterion = nn.MSELoss()loss = criterion(output, target)#至此我们就定一个损失函数 反向传播 我们只需要调用loss.backward()来反向传播权重，但是在开始的时候需要清零现有的梯度，否则梯度将会与已有的梯度累计 1234net.zero_grad()print(net.conv1.bias.grad) #反向传播前打印从conv1的bias梯度loss.backward()print(net.conv1.bias.grad) #反向传播后 output： 12tensor([0., 0., 0., 0., 0., 0.])tensor([ 0.0084, 0.0019, -0.0179, -0.0212, 0.0067, -0.0096]) 下面介绍如何更新参数： 123456789import torch.optim as optim#create a SDG optimizer optimizer = optim.SGD(net.parameters(), lr=0.01)optimizer.zero_grad()output = net(input)loss = criterion(output, target)loss.backward()#更新参数optimizer.step() 到这里已经介绍完了Lenet5用Pytoch实现的主要部件，下一讲将讲解详细代码和训练过程]]></content>
      <categories>
        <category>学习笔记</category>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文笔记-LoopyNeuralNetaImitatingFeedbackLoopsInTheHumanBrain]]></title>
    <url>%2Fpost%2F%5B20190525%5D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-LoopyNeuralNetaImitatingFeedbackLoopsInTheHumanBrain%2F</url>
    <content type="text"><![CDATA[写在前面这篇论文笔记将以翻译加上李阿的个人注解的形式进行。因本人水平有限，难免会有地方遗漏或者错误，请大家发现后积极评论或者点击右下角按钮与李阿实时交流。 摘要 人工神经网络旨在仿生，但是在定义上是非循环计算图。作为一个结论，人工网络中的神经元仅仅只激活一次并且没有时间动态变化。这些属性都与神经科学教给我们关于人脑连接的知识相违背，特别是在谈论物体识别时。因此，我们提出了一种模拟大脑中反馈回路的方法，这种方法通过数次展开带有回路的神经网络并研究这些网络的属性。我们比较了不同版本的回路，其中包括有对输入进行乘法或者加法的。我们证明了回路神经网络在CIFAR-10数据集上比拥有同等参数的深层前馈网络、以及相同网络非加环的版本表现优异，在MNIST数据集表现一样优异。为了进一步的理解我们的模型，我们用在回路层中使用guided backprop可视化神经元，证明在更高的展开层相同的滤波器表现逐渐非线性化。进一步的，我们将回路解释为注意力机制，以及证明了输入图片产生输出图片回路输出的构成很像attention maps. Introduction 神经网络特别是深度神经网络在这些年成为新兴的领域已经有了很多行为研究。这是一个受大脑启发的模型，尽管每一个神经元只支持简单的、原始的功能但整个网络允许大脑执行复杂的任务，一个神经网络包含一系列相互连接的层。每一层神经元计算前一层的简单功能(翻译起来很奇怪哈，原文为each layer of neurons computes a simple function of the previous layer)，但是将许多层整合在一起运行最终的去执行一些列任意复杂的任务。行为研究因为计算能力的巨大提升发展迅速，并一举将神经网络转变为最先进的科技。计算机使用神经网络如今可以扮演个人助手的角色比如Siri和cortana，打电子游戏，和识别猫的视频。 然而，人工神经网络和自然界同类具有明显的不同；人工神经网络是有向无环图，但是我们大脑中的神经网络包含许多反馈环。事实上，神经科学告诉我们人类大脑的结构实际上是循环的。举个例子，证据充分的what pathway 和where path way这两种人类主要的视觉目标识别系统，包括了很多的反馈环导致了被称为top down attention的现象。这这篇文章中，我们提出了一个模型，我们称之为LNNS。更高级的，一个LNN模仿人脑中的循环结构并使用loop layers允许信息从更深的层回到低层的增强卷积神经网络。 在Introduction中作者首先简要介绍了神经网络，并提出其与人脑的不同之处，最后指出为了模仿人脑的循环结构设计了LNNS。 ourModel 1. Theoretical Model图一展示了我们提出模型的简单例子。在这个例子中我们使用的是卷积层，但是相同的想法也可以别应用到其他类型的层中。尽管神经网络一般是无环的，上面的模型包含了一些环。特别地，环的输出在作为输入再次送到第一层之前逐元素加到输入层。 如果这个圈能够进行下去直到结果收敛，那么这将是理想的。然而，通常收敛是不被保证的，也是不计算简便的。实际上这都不是仿生的，因为真实输出的大脑是一直在变化的。因此我们的大约设计这个带圈的结构，通过模仿少量的通路通过反馈圈。 为了完成这个，我们提出了一个相似与RNNs的机制。这个模型通过一个参数k（称之为展开系数）来进一步定义，这个参数决定了圈将被执行的次数。之所以被叫为圈是因为它非常相似与RNNs中的展开机制。比如，图一右边的示意图表明了左边的网络展开3次后网络将会发生什么。 通过圈的相加，期望LNNs在接下来的方式中提升普通的网络。 反馈机制通过允许更低层知道更高层特征 的权重，一个对更低层权重更好的选择将是可能的。 坚实的表现当展开数次后，即使一个浅的网络能够装配一个深度神经网络，但展开的神经 网络使用远远更少的参数当与同样深度的神经网络相比时。尽管参数数量的存在差异，仍希望两个网络都能提供相似的表达能力。如果这被发现时对的，LNNs能等效为复杂、深层网络坚实表现。 训练一个LNN十分相似与训练一个普通的神经网络。当LNN被 展开之后，前行传播就像标准的方式。后向传播也能以标准的方式在展开的LNN上去做。然而，因为在展开网络中各个层之间共享参数，梯度需要被不同地更新。比如，在图一中，我们将在每一个展开层中将每一层视为不同层，并像往常一样执行后向传播。然而，真实的梯度$W_1$将是每一层中梯度$W_1$的和。用公式表达： $dW_i=\sum\limits_{j=1}^kdW_{i,j}$ 其中$dW_i$是层$W_i$的梯度，$dW_{i,j}$表示$W_i$第j个展开的梯度。]]></content>
      <categories>
        <category>论文笔记</category>
        <category>上科大访问</category>
      </categories>
      <tags>
        <tag>论文笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HI Guys]]></title>
    <url>%2Fpost%2F%5B20190524%5Dhello-world%2F</url>
    <content type="text"><![CDATA[写给第一次见面的你 互联网宛如浩瀚的宇宙一样，太广袤，但是很幸运李阿的Home这个小小的blog网站能够在广袤无垠的互联网世界与你相遇，我相信这是天大的缘分，能将我的想法、我的思考呈现在你的面前。李阿的Home仅仅只是李阿表达自己、分享自己的平台，在这里我将和你分享论文笔记、技术教程、影评乐评、日志感悟等一切李阿可能有感而发的东西。李阿还左下角添加了两首耳熟能详的适合学习的音乐，一首是我在那一角落患过伤风，是当年步步高音乐手机的广告，不知道你还记不记得里面乔妹神仙一般的颜值！第二首是大家一定在英语课上听过的歌yesterday once more。希望这两首歌会让你喜欢，让你更好的学习！ 如果你觉得我的文章对你有所启发，那将是李阿的毕生荣幸，如果你觉得我的文章过于幼稚或者有所待商榷，欢迎和李阿进行交流，交换彼此的意见共同进步。李阿的Home十分欢迎大家交流意见、互换想法。 在这里李阿在每篇文章的下面设置了评论区，欢迎大家在评论区发表自己的看法和见解亦或者提出你的疑问。 在页面的右下角还设置了实时在线交流入口，也欢迎大家通过这个交流入口和李阿进行交流，李阿在看到的第一时间会回复你的。 在文章的下方还有分享功能，欢迎大家把喜欢的文章分享到各大平台，让更多的人参与进来。 同时，李阿也植入了赞赏功能，赞赏的目的不是发家致富，而是希望赢得你的支持和尊重，对原创、分享的支持和尊重，真是出于这个目的才开始了赞赏功能，希望你在觉得文章对你有所启发、解答了你的问题的时候可以多多支持李阿的Home！]]></content>
      <categories>
        <category>欢迎页</category>
      </categories>
      <tags>
        <tag>写在前面</tag>
      </tags>
  </entry>
</search>
